{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1a5bb-3ed8-480c-9b32-379fdc4e6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e9f1b9-81a2-422f-89b4-46923b5da14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27463297-f8b3-4042-8ab3-8ea0083ac86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ee99ae-254c-45d1-9329-a0977aa5d947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::719742385994:role/SageMakerLLMRole'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eab4d86-cd3a-4174-a183-b3484f101305",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"model_id\": \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n",
    "    \"epochs\": 2,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"lr\": 2e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268b8e0c-928a-420d-921f-a7427b4ad502",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = HuggingFace(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./script\",\n",
    "    role=role,\n",
    "    transformers_version=\"4.36\",\n",
    "    pytorch_version=\"2.1\",\n",
    "    py_version=\"py310\",\n",
    "    instance_type=\"ml.g5.xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=\"s3://llm-model-artifacts-girish/models/\",\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee276d1-6bd5-4f81-95aa-cd3e6b18d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2025-11-19-11-16-01-374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-19 11:16:02 Starting - Starting the training job\n",
      "2025-11-19 11:16:02 Pending - Training job waiting for capacity......\n",
      "2025-11-19 11:16:37 Pending - Preparing the instances for training...\n",
      "2025-11-19 11:17:27 Downloading - Downloading the training image........................\n",
      "2025-11-19 11:21:35 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:46,593 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:46,612 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:46,622 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:46,628 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:48,538 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:48,696 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:48,731 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:48,746 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 2,\n",
      "        \"lr\": 2e-05,\n",
      "        \"model_id\": \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n",
      "        \"per_device_train_batch_size\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2025-11-19-11-16-01-374\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://llm-model-artifacts-girish/huggingface-pytorch-training-2025-11-19-11-16-01-374/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":2,\"lr\":2e-05,\"model_id\":\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\"per_device_train_batch_size\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://llm-model-artifacts-girish/huggingface-pytorch-training-2025-11-19-11-16-01-374/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"lr\":2e-05,\"model_id\":\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\"per_device_train_batch_size\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2025-11-19-11-16-01-374\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://llm-model-artifacts-girish/huggingface-pytorch-training-2025-11-19-11-16-01-374/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"2\",\"--lr\",\"2e-05\",\"--model_id\",\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\"--per_device_train_batch_size\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_LR=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 train.py --epochs 2 --lr 2e-05 --model_id TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T --per_device_train_batch_size 2\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:48,746 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-11-19 11:21:48,747 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m===== Loading Dataset =====\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 5 examples [00:00, 1206.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/5 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 5/5 [00:00<00:00, 1571.37 examples/s]\u001b[0m\n",
      "\u001b[34m===== Loading Tokenizer =====\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/5 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 5/5 [00:00<00:00, 655.75 examples/s]\u001b[0m\n",
      "\u001b[34m===== Loading Base Model in 4bit =====\u001b[0m\n",
      "\u001b[34m===== Applying QLoRA =====\u001b[0m\n",
      "\u001b[34m===== Setting Training Params =====\u001b[0m\n",
      "\u001b[34m===== Starting Training =====\u001b[0m\n",
      "\u001b[34m0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m50%|█████     | 1/2 [00:03<00:03,  3.26s/it]\u001b[0m\n",
      "\n",
      "2025-11-19 11:22:45 Uploading - Uploading generated training model\u001b[34m100%|██████████| 2/2 [00:04<00:00,  1.96s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 4.3389, 'train_samples_per_second': 2.305, 'train_steps_per_second': 0.461, 'train_loss': 3.7419145107269287, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:04<00:00,  1.96s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 2/2 [00:04<00:00,  2.16s/it]\u001b[0m\n",
      "\u001b[34m===== Saving Model =====\u001b[0m\n",
      "\u001b[34m===== Training Completed Successfully =====\u001b[0m\n",
      "\u001b[34m2025-11-19 11:22:38,803 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-11-19 11:22:38,803 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-11-19 11:22:38,803 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-11-19 11:22:58 Completed - Training job completed\n",
      "Training seconds: 351\n",
      "Billable seconds: 351\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\n",
    "    \"train\": \"s3://llm-finetune-dataset-girish/datasets/\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0997d99a-fe1f-4c36-8048-7ada20ec30d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;cell line: 1&gt;:1                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 estimator.latest_training_job.model_data                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 # estimator.model_data</span>                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008700; text-decoration-color: #008700\">'_TrainingJob'</span> object has no attribute <span style=\"color: #008700; text-decoration-color: #008700\">'model_data'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in <cell line: 1>:1                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1 estimator.latest_training_job.model_data                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m# estimator.model_data\u001b[0m                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[38;2;0;135;0m'_TrainingJob'\u001b[0m object has no attribute \u001b[38;2;0;135;0m'model_data'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# estimator.latest_training_job.model_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb8a30d-2694-48a6-90d0-03ac56169cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://llm-model-artifacts-girish/models/huggingface-pytorch-training-2025-11-19-11-16-01-374/output/model.tar.gz'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69ee874-bceb-444a-9032-13020d6224b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;cell line: 1&gt;:1                                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 predictor = huggingface_estimator.deploy(                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>initial_instance_count=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>,                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>instance_type=<span style=\"color: #808000; text-decoration-color: #808000\">\"ml.g5.xlarge\"</span>                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>)                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008700; text-decoration-color: #008700\">'huggingface_estimator'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in <cell line: 1>:1                                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1 predictor = huggingface_estimator.deploy(                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m│   \u001b[0minitial_instance_count=\u001b[94m1\u001b[0m,                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m│   \u001b[0minstance_type=\u001b[33m\"\u001b[0m\u001b[33mml.g5.xlarge\u001b[0m\u001b[33m\"\u001b[0m                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m4 \u001b[0m)                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[38;2;0;135;0m'huggingface_estimator'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictor = huggingface_estimator.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type=\"ml.g5.xlarge\"\n",
    "# )\n",
    "\n",
    "# predictor.predict({\"inputs\": \"Explain AWS S3\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69111c63-9c43-4108-ba13-188cf64598af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to check all the accessible services inside your AWS Sagemaker\n",
    "\n",
    "# from sagemaker import image_uris\n",
    "\n",
    "# image_uris.retrieve(\n",
    "#     framework=\"huggingface\",\n",
    "#     region=\"ap-south-1\",   # change your region\n",
    "#     version=\"4.37.0\",\n",
    "#     image_scope=\"inference\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54030e21-e5b3-475e-8b18-f470cadce916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: girish-live-finetune-endpoint\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: girish-live-finetune-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint delete skipped/failed: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"girish-live-finetune-endpoint\".\n",
      "Deleted endpoint config: girish-live-finetune-endpoint\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "endpoint_name = \"girish-live-finetune-endpoint\"\n",
    "\n",
    "# 1. Delete endpoint (if it exists)\n",
    "try:\n",
    "    sess.delete_endpoint(endpoint_name)\n",
    "    print(f\"Deleted endpoint: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Endpoint delete skipped/failed: {e}\")\n",
    "\n",
    "# 2. Delete endpoint config (if it exists)\n",
    "try:\n",
    "    sess.delete_endpoint_config(endpoint_name)\n",
    "    print(f\"Deleted endpoint config: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Endpoint config delete skipped/failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4daf7-c8f0-454a-b6cf-9f4ef97e6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance_type=\"ml.g5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ac72943-aebf-4b14-b01e-e2e661df4a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://llm-model-artifacts-girish/models/huggingface-pytorch-training-2025-11-19-11-16-01-374/output/model.tar.gz), script artifact (inference), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-719742385994/huggingface-pytorch-inference-2025-11-22-19-05-01-750/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2025-11-22-19-05-03-548\n",
      "INFO:sagemaker:Creating endpoint-config with name girish-live-finetune-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name girish-live-finetune-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "## the code for the deployment\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# model = HuggingFaceModel(\n",
    "#     model_data=\"s3://llm-model-artifacts-girish/models/huggingface-pytorch-training-2025-11-19-11-16-01-374/output/model.tar.gz\",\n",
    "#     role=role,\n",
    "#     transformers_version=\"4.37.0\",\n",
    "#     pytorch_version=\"2.1.0\",\n",
    "#     py_version=\"py310\",\n",
    "# )\n",
    "\n",
    "model = HuggingFaceModel(\n",
    "    model_data=\"s3://llm-model-artifacts-girish/models/huggingface-pytorch-training-2025-11-19-11-16-01-374/output/model.tar.gz\",\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"inference\",\n",
    "    transformers_version=\"4.37.0\",\n",
    "    pytorch_version=\"2.1.0\",\n",
    "    py_version=\"py310\"\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\",\n",
    "    endpoint_name=\"girish-live-finetune-endpoint\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08c5c0-f577-4d53-9952-702da5a9e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## after the deployment URL will look like this\n",
    "# https://runtime.sagemaker.<region>.amazonaws.com/endpoints/live-finetune-endpoint/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673b065-e6f3-493a-8c09-9f7134f798a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## after the deployment URL will look like this\n",
    "https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/live-finetune-endpoint/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ef5f2a-1783-4953-bbd8-161b88778597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what Clinical trials have shown that adding Ezetimibe to statin therapy?\n",
      "Ezetimibe is a drug that is used to treat cholesterol. It is a statin. It is used to lower cholesterol in the blood.\n",
      "Ezetimibe is a drug that is used to treat cholesterol. It is a statin. It is used to lower cholesterol in the blood.\n",
      "Ezetimibe is a drug that is used to treat cholesterol. It is a statin. It is\n"
     ]
    }
   ],
   "source": [
    "# predictor.predict({\"inputs\": \"Explain AWS S3\"})\n",
    "# Metformin \n",
    "# predictor.predict({\"inputs\": \"Explain the mechanism of action of Metformin\"})\n",
    "print(predictor.predict({\"inputs\": \"what Clinical trials have shown that adding Ezetimibe to statin therapy?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7a1959e-6911-41a2-be69-30c5798676ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"what Clinical trials have shown that adding Ezetimibe to statin therapy?\\nEzetimibe is a drug that is used to treat cholesterol. It is a statin. It is used to lower cholesterol in the blood.\\nEzetimibe is a drug that is used to treat cholesterol. It is a statin. It is used to lower cholesterol in the blood.\\nEzetimibe is a drug that is used to treat cholesterol. It is a statin. It is\"\n"
     ]
    }
   ],
   "source": [
    "import boto3, json\n",
    "\n",
    "runtime = boto3.client(\"sagemaker-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "resp = runtime.invoke_endpoint(\n",
    "    EndpointName=\"girish-live-finetune-endpoint\",\n",
    "    ContentType=\"application/json\",\n",
    "    # Body=json.dumps({\"inputs\": \"Explain the mechanism of action of Metformin\"})\n",
    "    Body=json.dumps({\"inputs\": \"what Clinical trials have shown that adding Ezetimibe to statin therapy?\"})\n",
    ")\n",
    "\n",
    "print(resp[\"Body\"].read().decode())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
